{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking A,P,R Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I am checking that the identities of the A, P, and R atoms calculated in Notebook 01 with CrystalNN match the actual identities of the atoms from the main database. We will be comparing the dataframe pba_e_hull_df, from Notebook 01, with the json file pba_w_APR, which contains all of the data directly from the main database.\n",
    "\n",
    "I will also be importing the new file of PBAs. This new file contains significantly more PBAs than the old one, so we will be using this data for future analysis. Like in Notebook 1, I will eventually create a dataframe with the composition, composition formula (as string), e_hull, A/P/R atoms, and number of A atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Cleaning pba_w_APR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pba_w_APR is a json file. Let's first look to see if it's in the proper format to import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pba_w_APR.json', 'r') as file :\n",
    "  pba_json = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"R\": \"Co\", \"P\": \"Fe\", \"A\": \"Ca\", \"n\": 4, \"input\": {\"structure\": {\"@module\": \"pymatgen.core.structure\", \"@class\": \"Structure\", \"lattice\": {\"matrix\": [[9.95090252, -0.0003358, -0.0003358], [-0.0003358, 9.95090252, 0.0003358], [-0.0003358, 0.0003358, 9.95090252]], \"a\": 9.9509025313318, \"b\": 9.9509025313318, \"c\": 9.9509025313318, \"alpha\": 89.99613296435679, \"beta\": 90.00386703564321, \"gamma\": 90.00386703564321, \"volume\": 985.3429511575596}, \"sites\": [{\"species\": [{\"element\": \"Ca\", \"occu\": 1}], \"abc\": [0.75135993, 0.75127745, 0.75127745], \"xyz\": [7.476204862928603, 7.47588864272739, 7.47588864272739], \"label\": \"Ca\"}, {\"species\": [{\"element\": \"Ca\", \"occu\": 1}], \"abc\": [0.24872255, 0.24864007, 0.75127745], \"xyz\": [2.47467807727261, 2.474361857071396, 7.47588864272739], \"label\": \"Ca\"}, {\"species\": [{\"element\": \"Ca\", \"occu\": 1}], \"abc\": [0.24872255, 0.75127745, 0.24864007], \"xyz\": [2.47467807727261, 7.47588864272739, 2.474361857071396], \"label\": \"Ca\"}, {\"species\": [{\"element\": \"Ca\", \"occu\": 1\n"
     ]
    }
   ],
   "source": [
    "print(pba_json[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it's in the right format. We'll import the data using the loadfn method, which puts the data into a list of python dictionaries. This is the same method used in Notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monty.serialization import loadfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = loadfn('pba_w_APR.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's loop through data_1 and parse the composition and atom identities into a pandas dataframe, which we'll then use to compare with the previously created dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n"
     ]
    }
   ],
   "source": [
    "pba_APR_df = pd.DataFrame(index=range(len(data_1)),columns=['A_atom','P_atom','R_atom','n_A'])\n",
    "for i in range(len(data_1)):\n",
    "    try:\n",
    "        pba_APR_df.loc[i, 'P_atom'] = data_1[i]['P']\n",
    "        pba_APR_df.loc[i, 'R_atom'] = data_1[i]['R']\n",
    "        if 'A' in data_1[i]:\n",
    "            pba_APR_df.loc[i, 'A_atom'] = data_1[i]['A']\n",
    "        if 'n' in data_1[i]:\n",
    "            pba_APR_df.loc[i, 'n_A'] = data_1[1]['n']\n",
    "    except:\n",
    "        print(i) #the indices that are printed are for atoms that ran into an error i.e. there is not A,P, or R field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_atom</th>\n",
       "      <th>P_atom</th>\n",
       "      <th>R_atom</th>\n",
       "      <th>n_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ca</td>\n",
       "      <td>Fe</td>\n",
       "      <td>Co</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mg</td>\n",
       "      <td>Cr</td>\n",
       "      <td>Os</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ca</td>\n",
       "      <td>Fe</td>\n",
       "      <td>Mn</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ca</td>\n",
       "      <td>Mn</td>\n",
       "      <td>Os</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Li</td>\n",
       "      <td>Cr</td>\n",
       "      <td>Cr</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A_atom P_atom R_atom n_A\n",
       "0     Ca     Fe     Co   4\n",
       "1     Mg     Cr     Os   4\n",
       "2     Ca     Fe     Mn   4\n",
       "3     Ca     Mn     Os   4\n",
       "4     Li     Cr     Cr   4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pba_APR_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this data set is much longer than the dataset originally analyzed in Notebook 01. For the purposes of checking the A, P, and R atoms from Notebook 01, we won't worry too much about this right now.\n",
    "\n",
    "The method that we'll use is loop through the pba_e_hull_df, and for each structure we'll check that there is a corresponding structure in the pba_APR_df with the same A, P, and R atoms.\n",
    "\n",
    "If our CrystalNN method misclassified any of the atom identities in Notebook 01, then it likely will not match any of the entries in the pba_APR_df, so we'll know there was an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing pba_e_hull_df:\n",
    "# pba_e_hull_df_old = pd.read_csv('pba_e_hull_df_old.csv')\n",
    "# pba_e_hull_df_old.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pba_e_hull_df_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_errors = [] #This will be a list of the structures in the original df that do not correspond to any \n",
    "# # of the structures in pba_APR_df.\n",
    "# for i in range(len(pba_e_hull_df_old)):\n",
    "#     A_atom = pba_e_hull_df_old.iloc[i]['A_atom']\n",
    "#     P_atom = pba_e_hull_df_old.iloc[i]['P_atom']\n",
    "#     R_atom = pba_e_hull_df_old.iloc[i]['R_atom']\n",
    "#     A_entries = pba_APR_df[pba_APR_df['A_atom'] == A_atom]\n",
    "#     AP_entries = A_entries[A_entries['P_atom'] == P_atom]\n",
    "#     APR_entries = AP_entries[AP_entries['R_atom'] == R_atom]\n",
    "#     if len(APR_entries) == 0:\n",
    "#         list_of_errors.append(i)\n",
    "# print(list_of_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the list of erros is empty, so all of the structures from the Notebook 01 dataframe, pba_e_hull_df, have corresponding structures in this new dataframe. This indicates that our CrystalNN algorithm is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out structures with H or O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the new data contains significantly more structures, we will first filter out any structures containing H or O (because those aren't PBAs), and then we will see whether there are indeed additional PBAs in this data that weren't in the original file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's loop through the list of structures in data_1 and create a pymatgen entry for each. Then we'll check whether each structure contains H or O, and if it doesn't, we'll add its pymatgen structure to a list of PBAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatgen as mg\n",
    "from pymatgen.entries.computed_entries import ComputedEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pba_entries = []\n",
    "for i in range((len(data_1))):\n",
    "    #Creating pymatgen entry:\n",
    "    entry = ComputedEntry(composition=data_1[i]['input']['structure'].composition,\n",
    "                              energy=data_1[i]['output']['energy'],\n",
    "                              parameters = {\"nelect\": data_1[i]['input']['parameters']['NELECT'],\n",
    "                                            \"hubbards\": data_1[i]['input']['hubbards'],\n",
    "                                            \"potcar_spec\": data_1[i]['input']['potcar_spec'],\n",
    "                                            \"is_hubbard\": data_1[i]['input']['is_hubbard']})\n",
    "    \n",
    "    if 'H' in entry.composition or 'O' in entry.composition: #Filtering out structures with hydrogen or oxygen\n",
    "        pba_entries.append('')\n",
    "    elif entry.composition.as_dict()['C'] != 24 or entry.composition.as_dict()['N'] != 24:\n",
    "        #Filtering out structures that don't have 24 Cs or 24 Ns - these are also not PBAs\n",
    "        pba_entries.append('')\n",
    "    else:\n",
    "        pba_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pba_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3783"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking with Shyam, it turns out that there are repeats in the file because the same atoms can have various configurations within the PBA structure. Therefore, we should make the phase diagram with all of the PBA compositions, and then pymatgen will just calculate the lowest possible energy above hull for each composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen import MPRester\n",
    "mpr = MPRester(api_key='clRGHmBDgp1xt9zA')\n",
    "from pymatgen.entries.compatibility import MaterialsProjectCompatibility\n",
    "mpc = MaterialsProjectCompatibility()\n",
    "from pymatgen.analysis.phase_diagram import PhaseDiagram, PDPlotter\n",
    "import pymatgen.analysis.local_env as localenv\n",
    "crys = localenv.CrystalNN()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crystal_nn(struct):\n",
    "    '''\n",
    "    Returns the A, P, and R atoms of a PBA in a list [A,P,R].\n",
    "    struct is data in the form data_1[i]['input']['structure'] and must be a PBA.\n",
    "    Uses pymatgen's CrystalNN method.\n",
    "    '''\n",
    "    A_atom_nn,P_atom_nn, R_atom_nn = '','','' #Initializing A, P, and R atoms\n",
    "    for j in range(len(struct)): #Looping through all of the elements in the PBA\n",
    "        atom = struct[j].as_dict()['species'][0]['element']\n",
    "        \n",
    "        if atom == 'C' and len(R_atom_nn)==0:\n",
    "            nn_objs = crys.get_nn_info(struct, j) #getting the nearest neighbors for atom, which is the jth atom in struct\n",
    "            for k in range(len(nn_objs)):\n",
    "                nn = nn_objs[k]['site'].as_dict()['species'][0]['element']\n",
    "                if nn != 'N':\n",
    "                    R_atom_nn = nn\n",
    "                    break\n",
    "                    \n",
    "        elif atom == 'N' and len(P_atom_nn)==0:\n",
    "            nn_objs = crys.get_nn_info(struct, j) #getting the nearest neighbors for atom, which is the jth atom in struct\n",
    "            for k in range(len(nn_objs)):\n",
    "                nn = nn_objs[k]['site'].as_dict()['species'][0]['element']\n",
    "                if nn != 'C':\n",
    "                    P_atom_nn = nn\n",
    "                    break\n",
    "                    \n",
    "    for j in struct.composition.as_dict().keys():\n",
    "        if j not in [P_atom_nn,R_atom_nn,'C','N']:\n",
    "            A_atom_nn = j\n",
    "            break\n",
    "    return [A_atom_nn,P_atom_nn,R_atom_nn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpr.get_entries_in_chemsys(['Co','Fe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing pba_e_hull_df back into the workspace:\n",
    "# pba_e_hull_df = pd.read_csv('pba_e_hull_df_0_1224.csv')\n",
    "# pba_e_hull_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pba_e_hull_df = pd.DataFrame(index=range(len(pba_e_hull_df)),columns=['Composition','Formula','e_above_hull','A_atom','P_atom','R_atom','n_A'])\n",
    "for i in range(len(pba_e_hull_df)):\n",
    "    try:\n",
    "        if (i%20 == 0) or (i == 10):\n",
    "            print(str(i) + 'th iteration') #Just to make it easier to keep track of how the algorithm is running\n",
    "\n",
    "        struct = data_1[i]['input']['structure']\n",
    "        pba_entry = pba_entries[i]\n",
    "        if type(pba_entry) == str: #If the entry is string, then it was filtered out and we didn't create a pymatgen entry for it.\n",
    "            pba_e_hull_df.loc[i] =  np.nan\n",
    "            continue\n",
    "        comp = pba_entry.composition\n",
    "\n",
    "        comp_dict = {'structure': my_crystal_nn(struct)} #Using my custom CrystalNN function to get the A,P,R\n",
    "\n",
    "        if comp_dict['structure'][1] not in ['Mn', 'Fe', 'Cr', 'Co', 'Zn', 'V']:\n",
    "            pba_e_hull_df.loc[i] =  np.nan\n",
    "            continue \n",
    "        if comp_dict['structure'][2] not in ['Fe', 'Mn', 'Cr', 'Os', 'Co', 'V']:\n",
    "            pba_e_hull_df.loc[i] =  np.nan\n",
    "            continue #Here we skip over the PBAs that don't have P or R atoms in the hydrated \n",
    "\n",
    "        repeat_flag = False #initializing flag to indicate whether to move on to next structure because this is a repeat\n",
    "        for prev in range(i): #loop through previously created entriaes to check if there are for the exact same PBA:\n",
    "            if prev in pba_e_hull_df.index.values:\n",
    "                if ((comp_dict['structure'][0] == pba_e_hull_df.loc[prev, 'A_atom']) & \n",
    "                    (comp_dict['structure'][1] == pba_e_hull_df.loc[prev, 'P_atom']) & \n",
    "                    (comp_dict['structure'][2] == pba_e_hull_df.loc[prev, 'R_atom']) &\n",
    "                    (comp.as_dict()[comp_dict['structure'][0]] == pba_e_hull_df.loc[prev,'n_A'])):\n",
    "                    repeat_flag = True\n",
    "                    break\n",
    "        if repeat_flag:\n",
    "            pba_e_hull_df.loc[i] =  np.nan\n",
    "            continue\n",
    "\n",
    "        #Making list of other PBAs from list pba_entries with the same composition:\n",
    "        same_comps = []\n",
    "        for j in range(len(pba_entries)):\n",
    "            if type(pba_entries[j]) is str: #skip empty entries\n",
    "                continue\n",
    "            if pba_entries[j].composition == comp:\n",
    "                same_comps.append([pba_entries[j],j])\n",
    "\n",
    "        for k in range(len(same_comps)):\n",
    "            comp_dict[same_comps[k][1]] = my_crystal_nn(data_1[same_comps[k][1]]['input']['structure'])\n",
    "        #comp_dict is now a dictionary of all structures in data_1 with the same composition. The dictionary index\n",
    "        #is the index of the structure in data_1, and the value is a list of the [A,P,R] atom identities.\n",
    "\n",
    "        for k in range(len(same_comps)):\n",
    "            if comp_dict[same_comps[k][1]][1] != comp_dict['structure'][1] or comp_dict[same_comps[k][1]][2] != comp_dict['structure'][2]:\n",
    "                del comp_dict[same_comps[k][1]]\n",
    "        #comp_dict is now a dictionary of the structures in data_1 with same composition AND same A,P,R atoms\n",
    "\n",
    "        #We also want to delete the structures with different APR atoms dictionary from the same_comp list.\n",
    "        same_comps_and_APR = []\n",
    "        for k in range(len(same_comps)):\n",
    "            if same_comps[k][1] in comp_dict.keys(): #check if the index for that structure is in the comp_dict keys\n",
    "                same_comps_and_APR.append(same_comps[k][0])\n",
    "        #same_comps_and_APR is now a list of the pymatgen entries with the same composition and APR atoms\n",
    "\n",
    "        #Accessing MP data for structures with the any of the same atoms:\n",
    "        comp_atoms = comp.as_dict().keys()\n",
    "        entries = mpr.get_entries_in_chemsys(comp_atoms)\n",
    "\n",
    "        #Checking if the internet stopped working and we have to wait for it to start working:\n",
    "        while len(entries) == 0:\n",
    "            print('No internet on loop ' + str(i))\n",
    "            time.sleep(30)\n",
    "            entries = mpr.get_entries_in_chemsys(comp_atoms)\n",
    "\n",
    "        #Adding our pbas to this list of pymatgen entries:\n",
    "        entries = entries + same_comps_and_APR\n",
    "\n",
    "        #Applying correction using MPRester:\n",
    "        corrected_entries = mpc.process_entries(entries)\n",
    "\n",
    "        #Making phase diagram and accessing e_above_hull:\n",
    "        phase_d = PhaseDiagram(corrected_entries)\n",
    "\n",
    "        #Looping through the PBA structures to find the lowest energy above hull value:\n",
    "        e_above_hull_list = []\n",
    "        for k in range(1,len(same_comps_and_APR)+1):\n",
    "            e_above_hull_list.append(phase_d.get_e_above_hull(corrected_entries[-k]))\n",
    "        e_above_hull = min(e_above_hull_list)\n",
    "\n",
    "        #Adding the values known so far to the main df:\n",
    "    #     pba_e_hull_df.loc[i, 'Composition'] = comp\n",
    "        pba_e_hull_df.loc[i, 'Formula'] = comp.formula\n",
    "        pba_e_hull_df.loc[i, 'e_above_hull'] = e_above_hull\n",
    "\n",
    "        #Adding the A, P, and R atoms to main df:\n",
    "        pba_e_hull_df.loc[i, 'A_atom'] = comp_dict['structure'][0]\n",
    "        pba_e_hull_df.loc[i, 'P_atom'] = comp_dict['structure'][1]\n",
    "        pba_e_hull_df.loc[i, 'R_atom'] = comp_dict['structure'][2]\n",
    "        pba_e_hull_df.loc[i, 'n_A'] = comp.as_dict()[comp_dict['structure'][0]]\n",
    "\n",
    "        #Saving to csv: (this way, if code stops midway, previous work isn't lost)\n",
    "        pba_e_hull_df.to_csv('pba_e_hull_df_0_all.csv')\n",
    "    except:\n",
    "        print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pba_e_hull_df = pba_e_hull_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to file as pba_e_hull_df.csv\n",
    "pba_e_hull_df.to_csv('pba_e_hull_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing pba_e_hull_df back into the workspace:\n",
    "# pba_e_hull_df = pd.read_csv('pba_e_hull_df.csv')\n",
    "# pba_e_hull_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
